{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NLP Project : Disaster Tweets\n\nThis notebook will document our NLP learning process.\n\n---\n\n### *Data*\n\n- train.csv : the training set\n- test.csv : the test set\n- sample_submission.csv : a sample submission example\n\n\n## *Columns*\n\n* *id* : a unique identifier for each tweet\n* *text* : the text of the tweet\n* *location* : the location the tweet was sent from (may be blank)\n* *keyword* : a particular keyword from the tweet (may be blank)\n* *target* : in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n\n### *Goal*\n\n**Here, we are predicting whether a given tweet is about a real disaster or not. This is a binary classification problem.**\n\n\n---\n\n## References\n\n- https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert\n- https://www.kaggle.com/faressayah/natural-language-processing-nlp-for-beginners\n- https://www.kaggle.com/pavansanagapati/knowledge-graph-nlp-tutorial-bert-spacy-nltk/notebook\n- https://www.kaggle.com/shahules/basic-eda-cleaning-and-glove\n- https://www.kaggle.com/frankmollard/nlp-a-gentle-introduction-lstm-word2vec-bert\n- https://www.kaggle.com/xhlulu/disaster-nlp-keras-bert-using-tfhub/\n---","metadata":{"_uuid":"46ef52c6-01c5-4de5-b906-9fba57b57cd9","_cell_guid":"ebc3950a-985a-4854-97e6-3b01dc6a0b68","trusted":true}},{"cell_type":"markdown","source":"## Libraries import","metadata":{"_uuid":"0dae9d81-54c8-4bf4-aac5-cc2fc3cfa476","_cell_guid":"2042ecb3-3518-4973-8d43-dcd0c053b6f2","trusted":true}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom wordcloud import WordCloud\n\nimport missingno as msno\n\nfrom tqdm import tqdm\n\n# Nltk libraries\nimport nltk\nfrom nltk import ngrams\n\nimport re\nimport string\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, classification_report","metadata":{"_uuid":"bdb31331-8afc-4044-b8d8-a8d893cf83a5","_cell_guid":"c09f58a6-90d8-4440-b357-f8b56124f113","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:32:56.078117Z","iopub.execute_input":"2021-12-21T09:32:56.078394Z","iopub.status.idle":"2021-12-21T09:32:56.086935Z","shell.execute_reply.started":"2021-12-21T09:32:56.078351Z","shell.execute_reply":"2021-12-21T09:32:56.085888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{"_uuid":"2651fa8c-a022-4690-a619-d7b84c2ae460","_cell_guid":"c9ea7361-8086-48b1-ab44-5388db81a013","trusted":true}},{"cell_type":"markdown","source":" ### Train dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('../input/nlp-getting-started/train.csv')\ndf_train.head()","metadata":{"_uuid":"edcfef9a-d4d7-451a-881a-ff41e10d04e1","_cell_guid":"19608c01-18d7-476f-a922-2a02d713c694","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:00.311726Z","iopub.execute_input":"2021-12-21T09:33:00.313155Z","iopub.status.idle":"2021-12-21T09:33:00.385654Z","shell.execute_reply.started":"2021-12-21T09:33:00.313097Z","shell.execute_reply":"2021-12-21T09:33:00.384664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test dataset","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('../input/nlp-getting-started/test.csv')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:02.209724Z","iopub.execute_input":"2021-12-21T09:33:02.210622Z","iopub.status.idle":"2021-12-21T09:33:02.246938Z","shell.execute_reply.started":"2021-12-21T09:33:02.210569Z","shell.execute_reply":"2021-12-21T09:33:02.245888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Target values are not avaible in Kaggle's test set. \n\n> **Gunes Evitan ([@gunesevitan](https://www.kaggle.com/gunesevitan)) wrote:**\n> Test set labels can be found on [this](https://www.figure-eight.com/data-for-everyone/) website. Dataset is named **Disasters on social media**. This is how people are submitting perfect scores. Other \"Getting Started\" competitions also have their test labels available. The main point of \"Getting Started\" competitions is **learning and sharing**, and perfect score doesn't mean anything. \n> According to [@philculliton](https://www.kaggle.com/philculliton) from Kaggle Team, competitors who use test set labels in any way are not eligible to win AutoML prize. There are no other penalties for using them.\n","metadata":{}},{"cell_type":"code","source":"df_leak = pd.read_csv('../input/diastertweets/socialmedia-disaster-tweets-DFE.csv', encoding ='ISO-8859-1')[[\"choose_one\", \"text\"]]\n\ndf_leak['target'] = (df_leak['choose_one'] == 'Relevant').astype(np.int8)\ndf_leak.drop(columns=['choose_one'], inplace=True)\n\ndf_test = df_test.merge(df_leak, on=['text'])\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:04.877341Z","iopub.execute_input":"2021-12-21T09:33:04.877658Z","iopub.status.idle":"2021-12-21T09:33:04.994769Z","shell.execute_reply.started":"2021-12-21T09:33:04.877611Z","shell.execute_reply":"2021-12-21T09:33:04.993845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataframes Information","metadata":{}},{"cell_type":"code","source":"print(df_train.info())\nprint(df_test.info())","metadata":{"_uuid":"22104290-bd72-46cf-a471-183f28279764","_cell_guid":"b86b4a9c-4d2b-49f9-b314-e62b7129b7bd","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:06.811731Z","iopub.execute_input":"2021-12-21T09:33:06.812039Z","iopub.status.idle":"2021-12-21T09:33:06.845409Z","shell.execute_reply.started":"2021-12-21T09:33:06.811975Z","shell.execute_reply":"2021-12-21T09:33:06.844373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for duplicates","metadata":{}},{"cell_type":"code","source":"print(df_train.duplicated().sum())\nprint(df_test.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:09.402536Z","iopub.execute_input":"2021-12-21T09:33:09.402845Z","iopub.status.idle":"2021-12-21T09:33:09.425879Z","shell.execute_reply.started":"2021-12-21T09:33:09.402799Z","shell.execute_reply":"2021-12-21T09:33:09.424729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no duplicates in the train set, but 193 duplcates in the test set.\n\n## Drop duplicates in test set","metadata":{}},{"cell_type":"code","source":"df_test = df_test.drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:11.048261Z","iopub.execute_input":"2021-12-21T09:33:11.048811Z","iopub.status.idle":"2021-12-21T09:33:11.060829Z","shell.execute_reply.started":"2021-12-21T09:33:11.048777Z","shell.execute_reply":"2021-12-21T09:33:11.059769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check for missing values","metadata":{"_uuid":"cd3ccef2-2b8d-4db0-9b97-18abc28e63e3","_cell_guid":"64bc516c-3eaa-4378-a878-293d6fd72cc9","trusted":true}},{"cell_type":"code","source":"df_train.isna().mean()*100","metadata":{"_uuid":"b4a844da-3225-4584-a6d4-b4644a757cc8","_cell_guid":"d5e4b183-93fb-4b6f-99aa-1d9ccf21363c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:14.30538Z","iopub.execute_input":"2021-12-21T09:33:14.305683Z","iopub.status.idle":"2021-12-21T09:33:14.327759Z","shell.execute_reply.started":"2021-12-21T09:33:14.305636Z","shell.execute_reply":"2021-12-21T09:33:14.326502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isna().mean()*100","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:16.040323Z","iopub.execute_input":"2021-12-21T09:33:16.040636Z","iopub.status.idle":"2021-12-21T09:33:16.053874Z","shell.execute_reply.started":"2021-12-21T09:33:16.040606Z","shell.execute_reply":"2021-12-21T09:33:16.052542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the train set :\n- $33.27\\%$ of location and\n- $0.80\\%$ of keyword are missing.\n\nFor the test set :\n- $34.36\\%$ of location and\n- $0.80\\%$ of keyword are missing.","metadata":{"_uuid":"1b771295-96f7-4037-be01-97a09ca67871","_cell_guid":"96805bb7-96a8-437e-b468-666e259228ae","trusted":true}},{"cell_type":"markdown","source":"## Proportion of missing data Visualization","metadata":{"_uuid":"a317dadf-fd2f-4558-ab22-80614220e661","_cell_guid":"3b129bac-169d-408d-850d-4eced081c098","trusted":true}},{"cell_type":"markdown","source":"### Train set","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_train)","metadata":{"_uuid":"47e50045-11c5-4c16-8910-3dff2508877c","_cell_guid":"5983d21a-7641-42ce-9e26-b742971e6363","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:19.093729Z","iopub.execute_input":"2021-12-21T09:33:19.094602Z","iopub.status.idle":"2021-12-21T09:33:19.653103Z","shell.execute_reply.started":"2021-12-21T09:33:19.094551Z","shell.execute_reply":"2021-12-21T09:33:19.651859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test set","metadata":{}},{"cell_type":"code","source":"msno.matrix(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:22.225289Z","iopub.execute_input":"2021-12-21T09:33:22.226036Z","iopub.status.idle":"2021-12-21T09:33:22.777225Z","shell.execute_reply.started":"2021-12-21T09:33:22.225971Z","shell.execute_reply":"2021-12-21T09:33:22.776311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deal with missing values\n\n- When a location is missing, it is going to be replaced by \"unknown-location\"\n- When a keyword is missing, it is going to be replaced by \"unknown-keyword\"","metadata":{"_uuid":"992681e1-d46c-43c8-ae06-34e271f9b3e8","_cell_guid":"a601ceb9-24ad-401c-bec8-258ab2b14b29","trusted":true}},{"cell_type":"code","source":"df_train.location = df_train.location.fillna('unknown-location')\ndf_train.keyword = df_train.keyword.fillna('Unknown-keyword')\ndf_test.location = df_test.location.fillna('unknown-location')\ndf_test.keyword = df_test.keyword.fillna('Unknown-keyword')","metadata":{"_uuid":"429055ae-e289-4c53-aa77-080c1993bc0b","_cell_guid":"6dfdc92f-39da-4f7c-8d55-0649088c374c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:25.107777Z","iopub.execute_input":"2021-12-21T09:33:25.108357Z","iopub.status.idle":"2021-12-21T09:33:25.120927Z","shell.execute_reply.started":"2021-12-21T09:33:25.108302Z","shell.execute_reply":"2021-12-21T09:33:25.119813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## Tweets exploration by target","metadata":{}},{"cell_type":"code","source":"df_train.iloc[:,1:].groupby(['target'])['text'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:27.736725Z","iopub.execute_input":"2021-12-21T09:33:27.737278Z","iopub.status.idle":"2021-12-21T09:33:27.765983Z","shell.execute_reply.started":"2021-12-21T09:33:27.737231Z","shell.execute_reply":"2021-12-21T09:33:27.765008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.iloc[:,1:].groupby(['target'])['text'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:28.923501Z","iopub.execute_input":"2021-12-21T09:33:28.924228Z","iopub.status.idle":"2021-12-21T09:33:28.94999Z","shell.execute_reply.started":"2021-12-21T09:33:28.924194Z","shell.execute_reply":"2021-12-21T09:33:28.948975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Traget distribution in dataset","metadata":{"_uuid":"d0bb3431-0778-482f-95fc-2172a68c42a2","_cell_guid":"cb570a41-8156-48ed-b314-9a43261b8fa4","trusted":true}},{"cell_type":"markdown","source":"### Countplot","metadata":{"_uuid":"75731f7e-22d8-471a-b794-be9815ce85c0","_cell_guid":"f065ea00-f2a4-4642-bb24-400cddbe59f8","trusted":true}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(16,8))\nsns.countplot(x='target', data=df_train, palette='hls', ax=ax[0])\nax[0].set_title('Traget distribution in train set')\nsns.countplot(x='target', data=df_test, palette='hls', ax=ax[1])\nax[1].set_title('Traget distribution in test set')\nplt.tight_layout()","metadata":{"_uuid":"de67851f-63ee-4c74-a60a-443b78014553","_cell_guid":"689383d2-d499-4b51-9c4d-aeb19b525790","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:31.044964Z","iopub.execute_input":"2021-12-21T09:33:31.045891Z","iopub.status.idle":"2021-12-21T09:33:31.430576Z","shell.execute_reply.started":"2021-12-21T09:33:31.045855Z","shell.execute_reply":"2021-12-21T09:33:31.429644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pie chart","metadata":{"_uuid":"6325547d-c470-4f1d-9052-e0962d3fedb1","_cell_guid":"434e2efc-31f4-46aa-aad7-bdcbd13b47d4","trusted":true}},{"cell_type":"code","source":"v1 = df_train['target'].value_counts()\nv2 = df_test['target'].value_counts()\nlabels = [0, 1]\n\n\nfig = plt.figure(figsize=(16,8))\n\nax1 = plt.subplot2grid((1,2),(0,0))\nplt.pie(v1, labels=labels, colors = ['grey','red'], autopct='%.0f%%')\nplt.title('Train set')\n\nax2 = plt.subplot2grid((1,2),(0, 1))\nplt.pie(v2, labels=labels, colors = ['grey','red'], autopct='%.0f%%')\nplt.title('Test set')\n\nplt.show()","metadata":{"_uuid":"8b92a792-78d8-4904-a8ce-4aa6ec298446","_cell_guid":"822deb7a-e841-43fb-aee4-7558cfb4bd46","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:33.539594Z","iopub.execute_input":"2021-12-21T09:33:33.540688Z","iopub.status.idle":"2021-12-21T09:33:33.846518Z","shell.execute_reply.started":"2021-12-21T09:33:33.540641Z","shell.execute_reply":"2021-12-21T09:33:33.845529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Location variation in dataset","metadata":{"_uuid":"eb54d4ec-38fc-4bea-9292-a22319b50dca","_cell_guid":"1fbf79ff-bbd5-4a21-bb63-8fb1901a105b","trusted":true}},{"cell_type":"code","source":"train_1 = df_train[df_train['target']==1].reset_index(drop=True)\ntrain_0 = df_train[df_train['target']==0].reset_index(drop=True)\ntest_1 = df_test[df_test['target']==1].reset_index(drop=True)\ntest_0 = df_test[df_test['target']==0].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:36.493866Z","iopub.execute_input":"2021-12-21T09:33:36.494639Z","iopub.status.idle":"2021-12-21T09:33:36.505928Z","shell.execute_reply.started":"2021-12-21T09:33:36.494603Z","shell.execute_reply":"2021-12-21T09:33:36.504744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = make_subplots(rows=1, cols=2)\nfig2 = make_subplots(rows=1, cols=2)\n\ntrace1 = go.Histogram(x=train_1.location,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Train set', marker_color='#a63048')\ntrace2 = go.Histogram(x=test_1.location,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Test set', marker_color='#d4687e')\n\ntrace3 = go.Histogram(x=train_0.location,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Train set', marker_color='#52d298')\ntrace4 = go.Histogram(x=test_0.location,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Test set', marker_color='#c1f8d8')\n\nfig1.add_trace(trace1, 1, 1)\nfig1.add_trace(trace2, 1, 2)\nfig1.update_layout(title_text='Location variation in dataset for target = 1')\nfig1.show()\n\nfig2.add_trace(trace3, 1, 1)\nfig2.add_trace(trace4, 1, 2)\nfig2.update_layout(title_text='Location variation in dataset for target = 0')\nfig2.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:33:38.095228Z","iopub.execute_input":"2021-12-21T09:33:38.095555Z","iopub.status.idle":"2021-12-21T09:33:38.474208Z","shell.execute_reply.started":"2021-12-21T09:33:38.095524Z","shell.execute_reply":"2021-12-21T09:33:38.473197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Keywords variation in dataset","metadata":{"_uuid":"3827cf37-f9d9-42c7-9654-dcd0d07954a4","_cell_guid":"b0bb2e6b-7c03-4879-87d6-3f86dbf9e70c","trusted":true}},{"cell_type":"code","source":"fig1 = make_subplots(rows=1, cols=2)\nfig2 = make_subplots(rows=1, cols=2)\n\ntrace1 = go.Histogram(x=train_1.keyword,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Train set', marker_color='#a63048')\ntrace2 = go.Histogram(x=test_1.keyword,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Test set', marker_color='#d4687e')\n\ntrace3 = go.Histogram(x=train_0.keyword,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Train set', marker_color='#52d298')\ntrace4 = go.Histogram(x=test_0.keyword,\n                      xbins=dict(\n                      start=0,\n                      end=15), name='Test set', marker_color='#c1f8d8')\n\nfig1.add_trace(trace1, 1, 1)\nfig1.add_trace(trace2, 1, 2)\nfig1.update_layout(title_text='Keywords variation in dataset for target = 1')\nfig1.show()\n\nfig2.add_trace(trace3, 1, 1)\nfig2.add_trace(trace4, 1, 2)\nfig2.update_layout(title_text='Keywords variation in dataset for target = 0')\nfig2.show()","metadata":{"_uuid":"82f4ea49-2851-4029-8f3b-a26a1d88a936","_cell_guid":"def5dd50-a44c-48b3-add0-6bf6f6e98f39","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:33:42.274753Z","iopub.execute_input":"2021-12-21T09:33:42.275465Z","iopub.status.idle":"2021-12-21T09:33:42.400222Z","shell.execute_reply.started":"2021-12-21T09:33:42.275431Z","shell.execute_reply":"2021-12-21T09:33:42.399337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Meta features visualization\nVisualization below were hugely inspired by [@gunesevitan](https://www.kaggle.com/gunesevitan)'s submission.","metadata":{}},{"cell_type":"code","source":"token = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\nstopW = nltk.corpus.stopwords.words('english')\n\n# word_count\ndf_train['word_count'] = df_train['text'].apply(lambda x: len(token.tokenize(str(x))))\ndf_test['word_count'] = df_test['text'].apply(lambda x: len(token.tokenize(str(x))))\n\n# unique_word_count\ndf_train['unique_word_count'] = df_train['text'].apply(lambda x: len(set(token.tokenize(str(x)))))\ndf_test['unique_word_count'] = df_test['text'].apply(lambda x: len(set(token.tokenize(str(x)))))\n\n# stop_word_count\ndf_train['stop_word_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in stopW]))\ndf_test['stop_word_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in stopW]))\n\n# url_count\ndf_train['url_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\ndf_test['url_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n\n# mean_word_length\ndf_train['mean_word_length'] = df_train['text'].apply(lambda x: np.mean([len(w) for w in token.tokenize(str(x))]))\ndf_test['mean_word_length'] = df_test['text'].apply(lambda x: np.mean([len(w) for w in token.tokenize(str(x))]))\n\n# char_count\ndf_train['char_count'] = df_train['text'].apply(lambda x: len(str(x)))\ndf_test['char_count'] = df_test['text'].apply(lambda x: len(str(x)))\n\n# punctuation_count\ndf_train['punctuation_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\ndf_test['punctuation_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n\n# hashtag_count\ndf_train['hashtag_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\ndf_test['hashtag_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n\n# mention_count\ndf_train['mention_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\ndf_test['mention_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:34:19.226634Z","iopub.execute_input":"2021-12-21T09:34:19.227217Z","iopub.status.idle":"2021-12-21T09:34:20.365467Z","shell.execute_reply.started":"2021-12-21T09:34:19.227184Z","shell.execute_reply":"2021-12-21T09:34:20.364399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METAFEATURES = ['word_count', 'unique_word_count', 'stop_word_count', 'url_count', 'mean_word_length',\n                'char_count', 'punctuation_count', 'hashtag_count', 'mention_count']\nDISASTER_TWEETS = df_train['target'] == 1\n\nfig, axes = plt.subplots(ncols=2, nrows=len(METAFEATURES), figsize=(20, 50), dpi=100)\n\nfor i, feature in enumerate(METAFEATURES):\n    sns.histplot(df_train.loc[~DISASTER_TWEETS][feature], label='Not Disaster', ax=axes[i][0], color='grey')\n    sns.histplot(df_train.loc[DISASTER_TWEETS][feature], label='Disaster', ax=axes[i][0], color='#972139')\n\n    sns.histplot(df_train[feature], label='Training', ax=axes[i][1], color=\"#217497\")\n    sns.histplot(df_test[feature], label='Test', ax=axes[i][1], color=\"#dcf6d5\")\n    \n    for j in range(2):\n        axes[i][j].set_xlabel('')\n        axes[i][j].tick_params(axis='x', labelsize=12)\n        axes[i][j].tick_params(axis='y', labelsize=12)\n        axes[i][j].legend()\n    \n    axes[i][0].set_title(f'{feature} Target Distribution in Training Set', fontsize=13)\n    axes[i][1].set_title(f'{feature} Training & Test Set Distribution', fontsize=13)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:34:26.041963Z","iopub.execute_input":"2021-12-21T09:34:26.04233Z","iopub.status.idle":"2021-12-21T09:34:35.723057Z","shell.execute_reply.started":"2021-12-21T09:34:26.042276Z","shell.execute_reply":"2021-12-21T09:34:35.722157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deleting columns after visualization\ndf_train = df_train.drop(['word_count', 'unique_word_count', 'stop_word_count', 'url_count', \n               'mean_word_length','char_count', 'punctuation_count', 'hashtag_count', \n               'mention_count'], axis = 1)\n\ndf_test = df_test.drop(['word_count', 'unique_word_count', 'stop_word_count', 'url_count', \n               'mean_word_length','char_count', 'punctuation_count', 'hashtag_count', \n               'mention_count'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:34:35.725181Z","iopub.execute_input":"2021-12-21T09:34:35.725772Z","iopub.status.idle":"2021-12-21T09:34:35.740241Z","shell.execute_reply.started":"2021-12-21T09:34:35.725726Z","shell.execute_reply":"2021-12-21T09:34:35.738848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning\n\nThese steps of cleaning were applied :\n1. **Normalization**\n2. **Tokenization**\n3. **Remove stopwords**\n4. **Remove punctuation**\n5. **Lemmatization**\n6. **Remove digits**\n7. **Remove single letters**\n8. **Remove symbols**\n\nThis cleaning was done by using the function *preprocess* defined below.","metadata":{}},{"cell_type":"markdown","source":"## Proprocess functions","metadata":{"_uuid":"4c3f723e-8288-453f-8af8-1a9a13acc421","_cell_guid":"0da8a990-9b57-4ed5-8725-f53d08bbac2d","trusted":true}},{"cell_type":"code","source":"def remove_stopwords(sent):\n    stopW = nltk.corpus.stopwords.words('english')\n    stopW.extend(list(string.punctuation))\n    return [word for word in sent if word not in stopW]\n\ndef lemmatize(sent, join=False):\n    lemmatizer = nltk.stem.WordNetLemmatizer()\n    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(lemmatizer.lemmatize(w,'v'),'n'),'a') for w in sent]\n    if join:\n        return ' '.join(tokens)\n    else:\n        return tokens\n    \ndef remove_digits(sent):\n    return [word for word in sent if not re.match(r\"\\S*\\d+\\S*\", word)]\n\ndef remove_single_letters(sent):\n    return [word for word in sent if len(word) > 1]\n\ndef remove_noise(sent):\n    typos = [\"û_\", \"amp\", \"ûª\", \"http\", \"https\", \"co\", \"rt\", \n             \"ûªs\", \"@\", \"...\", \"ûªs\", \"ûò\", \"åè\", \"ìñ1\"]\n    return [word for word in sent if word not in typos]\n\ndef join_tweets(sent):\n    return \"  \".join(sent)\n\ndef preprocess(df):\n    # Lower casing\n    df['text_cleaned'] = df['text'].apply(lambda sent: sent.lower())\n    \n    # Tokenize\n    token = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n    df['text_cleaned'] = df['text_cleaned'].apply(token.tokenize)\n    \n    # New column : tweet lengths before cleaning\n    df['text_length_before'] = df.text_cleaned.apply(len)\n    \n    # Remove stopwords and punctuation\n    df['text_cleaned'] = df['text_cleaned'].apply(lambda sent: remove_stopwords(sent)).reset_index(drop=True)\n    \n    # Lemmatize\n    df['text_cleaned'] = df['text_cleaned'].apply(lambda sent: lemmatize(sent))\n    \n    # Remove digits\n    df['text_cleaned'] = df['text_cleaned'].apply(remove_digits).reset_index(drop=True)\n    \n    # Remove single letter\n    df['text_cleaned'] = df['text_cleaned'].apply(remove_single_letters).reset_index(drop=True)\n    \n    # Remove weird symbols\n    df['text_cleaned'] = df['text_cleaned'].apply(remove_noise).reset_index(drop=True)\n    \n    # New column : tweet lengths after cleaning\n    df['text_length_after'] = df.text_cleaned.apply(len)\n    \n    # Join words into one str\n    df['text_cleaned'] = df['text_cleaned'].apply(join_tweets)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:34:39.20676Z","iopub.execute_input":"2021-12-21T09:34:39.207086Z","iopub.status.idle":"2021-12-21T09:34:39.22467Z","shell.execute_reply.started":"2021-12-21T09:34:39.207054Z","shell.execute_reply":"2021-12-21T09:34:39.223357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Applying preprocess on dataset","metadata":{}},{"cell_type":"code","source":"df_train = preprocess(df_train)\ndf_test = preprocess(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:34:44.004948Z","iopub.execute_input":"2021-12-21T09:34:44.005307Z","iopub.status.idle":"2021-12-21T09:34:50.461022Z","shell.execute_reply.started":"2021-12-21T09:34:44.005277Z","shell.execute_reply":"2021-12-21T09:34:50.459865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tweets length distribution by target before and after cleaning","metadata":{"_uuid":"777d5a58-ac91-4b69-a1d3-42f31a6e4a44","_cell_guid":"a825ff13-40bb-4d1a-b86e-e68a64b56587","trusted":true}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(16,8))\nsns.histplot(data = df_train, x = \"text_length_before\", element = \"step\", color='grey', ax=ax[0], label='before cleaning')\nsns.histplot(data = df_train, x = \"text_length_after\", element = \"step\", color='yellow', ax=ax[0], label='after cleaning')\nax[0].set_title('Tweets length distribution in train set')\nax[0].legend()\nsns.histplot(data = df_test, x = \"text_length_before\", element = \"step\", color='grey', ax=ax[1], label='before cleaning')\nsns.histplot(data = df_test, x = \"text_length_after\", element = \"step\", color='yellow', ax=ax[1], label='after cleaning')\nax[1].set_title('Tweets length distribution in test set')\nax[1].legend()","metadata":{"_uuid":"68cf2b94-d95e-40ff-9096-091534a8195e","_cell_guid":"b4dc2b2a-2f6b-462d-b819-98b846df98dc","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-12-21T09:41:50.490804Z","iopub.execute_input":"2021-12-21T09:41:50.491105Z","iopub.status.idle":"2021-12-21T09:41:51.048955Z","shell.execute_reply.started":"2021-12-21T09:41:50.491076Z","shell.execute_reply":"2021-12-21T09:41:51.047966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wordclouds\n\n## Wordclouds preparation","metadata":{"_uuid":"fae446ce-2742-4b36-8155-a0d76750976d","_cell_guid":"2842d13c-fd78-45f6-8e44-c5b5a079de8c","trusted":true}},{"cell_type":"code","source":"train_1 = df_train[df_train['target']==1].reset_index(drop=True)\ntrain_0 = df_train[df_train['target']==0].reset_index(drop=True)\ntest_1 = df_test[df_test['target']==1].reset_index(drop=True)\ntest_0 = df_test[df_test['target']==0].reset_index(drop=True)\n\n# Train for target 1\ntexts_train_1 = []\nfor i in range(0, train_1.shape[0]):\n    texts_train_1.append(train_1['text_cleaned'][i])\nwordcloud1 = WordCloud(background_color='white', colormap=\"hot\").generate(\" \".join(texts_train_1))\n\n# Train for target 0\ntexts_train_0 = []\nfor i in range(0, train_0.shape[0]):\n    texts_train_0.append(train_0['text_cleaned'][i])\nwordcloud2 = WordCloud(background_color='white', colormap=\"cividis\").generate(\" \".join(texts_train_0))\n\n# Test for target 1\ntexts_test_1 = []\nfor i in range(0, test_1.shape[0]):\n    texts_test_1.append(test_1['text_cleaned'][i])\nwordcloud3 = WordCloud(background_color='white', colormap=\"hot\").generate(\" \".join(texts_test_1))\n\n# Test for target 0\ntexts_test_0 = []\nfor i in range(0, test_0.shape[0]):\n    texts_test_0.append(test_0['text_cleaned'][i])\nwordcloud4 = WordCloud(background_color='white', colormap=\"cividis\").generate(\" \".join(texts_test_0))","metadata":{"_uuid":"1dbb89ac-0c1f-4c26-a72d-f9f420e36843","_cell_guid":"2036bfdb-191d-46f1-a36c-1643e941e9a0","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize = (24, 14))\n\nplt.subplot(2,2,1)\nplt.imshow(wordcloud1)\nplt.axis('off')\nplt.title(\"Wordcloud train set target = 1\")\n\nplt.subplot(2,2,2)\nplt.imshow(wordcloud2)\nplt.axis('off')\nplt.title(\"Wordcloud train set target = 0\")\n\nplt.subplot(2,2,3)\nplt.imshow(wordcloud3)\nplt.axis('off')\nplt.title(\"Wordcloud test set target = 1\")\n\nplt.subplot(2,2,4)\nplt.imshow(wordcloud4)\nplt.axis('off')\nplt.title(\"Wordcloud test set target = 0\")\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification preparation\n\nWe will be using both machine learning and deep learning models. Let us first split the data.","metadata":{}},{"cell_type":"markdown","source":"## Splitting data","metadata":{}},{"cell_type":"code","source":"X = np.array(df_train.text_cleaned)\ny = np.array(df_train.target)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, shuffle=True, test_size=0.20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.array(df_test.text_cleaned)\ny_test = np.array(df_test.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vectorization","metadata":{}},{"cell_type":"markdown","source":"# Classification with Machine Learning\n\nA few models were tested using gridsearhCV with different vectorizations.\n\n**Models :**\n* MultinomialNB\n* Logistic Regression\n* SGD\n* Xgboost\n* SVM classifier\n\n\n**Vectorizers :**\n- CountVectorizer()\n- HashingVectorizer(),\n- TfidfVectorizer(stop_words='english',analyzer='word',ngram_range=(1,2)),\n- TfidfVectorizer(stop_words='english',analyzer='word',ngram_range=(2,3)),\n- TfidfVectorizer(stop_words='english',analyzer='word',ngram_range=(1,3))\n\nThe performances (considering the recall score) were pretty close but the best performing model was the SGD Classifier. We will be using the best performing combination of model and vectorizer.","metadata":{}},{"cell_type":"code","source":"vect = TfidfVectorizer(analyzer='word',ngram_range=(1,3))\n\nvect.fit(X_train)\nX_train_dtm = vect.transform(X_train)\nX_val_dtm = vect.transform(X_val)\nX_test_dtm = vect.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:02:19.618638Z","iopub.execute_input":"2021-12-21T09:02:19.619029Z","iopub.status.idle":"2021-12-21T09:02:19.728251Z","shell.execute_reply.started":"2021-12-21T09:02:19.618906Z","shell.execute_reply":"2021-12-21T09:02:19.726347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SGDClassifier()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time clf.fit(X_train_dtm, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict validation set","metadata":{}},{"cell_type":"code","source":"%time y_pred_val = clf.predict(X_val_dtm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy score for validation set","metadata":{}},{"cell_type":"code","source":"accuracy_score(y_val, y_pred_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recall Score","metadata":{}},{"cell_type":"code","source":"recall_score(y_val, y_pred_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### F1 Score for validation set","metadata":{}},{"cell_type":"code","source":"f1_score(y_val, y_pred_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix for validation set","metadata":{}},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_val, y_pred_val), annot=True, fmt='.4g', cmap='Reds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification report for validation set","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_val, y_pred_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict test set","metadata":{}},{"cell_type":"code","source":"%time y_pred_test = clf.predict(X_test_dtm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy score for test set","metadata":{}},{"cell_type":"code","source":"accuracy_score(y_test, y_pred_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recall Score","metadata":{}},{"cell_type":"code","source":"recall_score(y_test, y_pred_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### F1 Score for validation set","metadata":{}},{"cell_type":"code","source":"f1_score(y_test, y_pred_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion matrix for test set","metadata":{}},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True, fmt='.4g', cmap='Reds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification report for test set","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification with Deep Learning : Glove + LSTM","metadata":{}},{"cell_type":"code","source":"# Define x and y values for the deep\nx = df_train['text_cleaned'].values\ny = df_train['target'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the length of our vocabulary in train tweets\nfrom keras.preprocessing.text import Tokenizer\n\nword_tokenizer= Tokenizer()\nword_tokenizer.fit_on_texts(x)\n\nvocab_length = len(word_tokenizer.word_index) + 1\nvocab_length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### This cell retrieves the Glove dictionary that we use as a reference to convert the tokens referred to in;\n\n# Load GloVe 100D embeddings\nembeddings_dictionary = dict()\nembedding_dim = 100\n\nwith open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt') as fp:\n    for line in fp.readlines():\n        records = line.split()\n        word = records[0]\n        vector_dimensions = np.asarray(records[1:], dtype='float32')\n        embeddings_dictionary [word] = vector_dimensions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the GloVe Dictionnary to load embedding vectors of our tweets only for tokens that are mentionned there. If they don't, they are set to 0. \nembedding_matrix = np.zeros((vocab_length, embedding_dim))\nfor word, index in word_tokenizer.word_index.items():\n    embedding_vector = embeddings_dictionary.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Here we convert the tokens into numeric sequences that the DL machine can receive as input. Then, every sequence is padded with zeros to put all vectors at the same \"lentgh\"\nfrom nltk.tokenize import word_tokenize\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef embed(corpus): \n    return word_tokenizer.texts_to_sequences(corpus)\n\nlongest_sent = max(x, key=lambda sentence: len(word_tokenize(sentence)))\nsent_max_len = len(word_tokenize(longest_sent))\n\ntrain_pad_sent = pad_sequences(embed(x), sent_max_len, padding='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_pad_sent, y, test_size=0.20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's define the model \nfrom keras.models import Sequential\nfrom keras.initializers import Constant\nfrom keras.layers import (LSTM, \n                          Embedding, \n                          BatchNormalization,\n                          Dense, \n                          TimeDistributed, \n                          Dropout, \n                          Bidirectional,\n                          Flatten, \n                          GlobalMaxPool1D)\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.metrics import (\n    precision_score, \n    recall_score, \n    f1_score, \n    classification_report,\n    accuracy_score\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's define the model \ndef glove_lstm():\n    model = Sequential()\n    \n    model.add(Embedding(\n        input_dim=embedding_matrix.shape[0], \n        output_dim=embedding_matrix.shape[1], \n        weights = [embedding_matrix], \n        input_length= sent_max_len\n    ))\n    \n    model.add(Bidirectional(LSTM(\n        sent_max_len, \n        return_sequences = True, \n        recurrent_dropout=0.2\n    )))\n    \n    model.add(GlobalMaxPool1D())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(sent_max_len, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(sent_max_len, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation = 'sigmoid'))\n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\nmodel = glove_lstm()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'model.h5', \n    monitor = 'val_loss', \n    verbose = 1, \n    save_best_only = True\n)\nreduce_lr = ReduceLROnPlateau(\n    monitor = 'val_loss', \n    factor = 0.2, \n    verbose = 1, \n    patience = 5,                        \n    min_lr = 0.001\n)\nhistory = model.fit(\n    X_train, \n    y_train, \n    epochs = 7,\n    batch_size = 32,\n    validation_data = (X_val, y_val),\n    verbose = 1,\n    callbacks = [reduce_lr, checkpoint]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's evaluate the results!","metadata":{}},{"cell_type":"code","source":"history.history.keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glstm_scores = [['loss', 'val_loss'],['accuracy', 'val_accuracy']]\n# Visualize the loss\nfig, ax = plt.subplots(1, 2, figsize=(20, 5))\nfor idx in range(2):\n    ax[idx].plot(history.history[glstm_scores[idx][0]])\n    ax[idx].plot(history.history[glstm_scores[idx][1]])\n    ax[idx].legend([glstm_scores[idx][0], glstm_scores[idx][1]],fontsize=18)\n    ax[idx].set_xlabel('Epochs ',fontsize=16)\n    ax[idx].set_ylabel('Score',fontsize=16)\n    ax[idx].set_title(glstm_scores[idx][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = (model.predict(X_val) > 0.5).astype(\"int32\")\nsns.heatmap(confusion_matrix(y_val, y_preds), annot=True, fmt='.4g', cmap='Reds')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification : Bert\n\nThe steps bellow were hugely inspired by [@xhlulu](https://www.kaggle.com/xhlulu)'s submission.","metadata":{}},{"cell_type":"code","source":"!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\n\nimport tokenization","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(bert_layer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(clf_output)\n    \n    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    optimizer = SGD(learning_rate=1e-5, momentum=0.8)\n    model.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodule_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\nbert_layer = hub.KerasLayer(module_url, trainable=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input = bert_encode(df_train.text.values, tokenizer, max_len=160)\ntest_input = bert_encode(df_test.text.values, tokenizer, max_len=160)\ntrain_labels = df_train.target.values\ntest_labels = df_test.target.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(bert_layer, max_len=160)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time train_history = model.fit(train_input, train_labels, validation_split=0.2, epochs=12, verbose = 1, callbacks=[checkpoint], batch_size=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_history.history\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x = train_history.epoch, y = train_history.history['loss'], name=\"Train loss\"))\n\nfig.add_trace(go.Scatter(x = train_history.epoch, y = train_history.history['val_loss'], name=\"Validation Loss\"))\n\nfig.update_layout(\n    title=\"Bert performance\",\n    xaxis_title=\"Epochs\",\n    yaxis_title=\"Loss\")\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('model.h5')\n%time test_pred = model.predict(test_input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"test_pred = (test_pred > 0.5).astype(\"int32\")\nsns.heatmap(confusion_matrix(y_test, test_pred), annot=True, fmt='.4g', cmap='Reds')\nplt.title('Bert for test set')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accuracy Score","metadata":{}},{"cell_type":"code","source":"accuracy_score(y_test, test_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recall Score","metadata":{}},{"cell_type":"code","source":"recall_score(y_test, test_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## F1 Score","metadata":{}},{"cell_type":"code","source":"f1_score(y_test, test_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification report","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}